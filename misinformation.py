# -*- coding: utf-8 -*-
"""Misinformation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PgJ0D4EoxqtFAyOqqezwEkGlApDU1VqA
"""

!pip -q install pandas numpy scikit-learn matplotlib langdetect ftfy emoji imbalanced-learn

import pandas as pd, numpy as np, re, json, emoji
from langdetect import detect, LangDetectException
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle

from google.colab import drive
import zipfile
import os

# Mount Drive
drive.mount('/content/drive')

# List of datasets
datasets = {
    "News Detection": "/content/drive/My Drive/Innovation Project/News Detection.zip",
    "Misinformation": "/content/drive/My Drive/Innovation Project/Misinformation.zip",
    "FakeNewsNet": "/content/drive/My Drive/Innovation Project/FakeNewsNet.zip"
}

# Extract each dataset
for name, zip_path in datasets.items():
    extract_path = f"/content/Innovation_Project/{name.replace(' ', '_')}"
    os.makedirs(extract_path, exist_ok=True)

    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)

    print(f"Extracted {name} to: {extract_path}")

import os

base_path = "/content/Innovation_Project"

for dataset in ["News_Detection", "Misinformation", "FakeNewsNet"]:
    print(f"\nFiles in {dataset}:")
    print(os.listdir(os.path.join(base_path, dataset)))

import pandas as pd

#  Load News Detection dataset
news_df = pd.read_csv("/content/Innovation_Project/News_Detection/fake_and_real_news.csv")

#  Load Misinformation dataset (FAKE + TRUE separately, then merge)
misinfo_fake = pd.read_csv("/content/Innovation_Project/Misinformation/DataSet_Misinfo_FAKE.csv")
misinfo_true = pd.read_csv("/content/Innovation_Project/Misinformation/DataSet_Misinfo_TRUE.csv")

# Added a label column
misinfo_fake["label"] = "FAKE"
misinfo_true["label"] = "TRUE"

# Combine
misinfo_df = pd.concat([misinfo_fake, misinfo_true], ignore_index=True)

#  Load FakeNewsNet (BuzzFeed fake + real)
buzzfeed_fake = pd.read_csv("/content/Innovation_Project/FakeNewsNet/BuzzFeed_fake_news_content.csv")
buzzfeed_real = pd.read_csv("/content/Innovation_Project/FakeNewsNet/BuzzFeed_real_news_content.csv")

# Add labels
buzzfeed_fake["label"] = "FAKE"
buzzfeed_real["label"] = "REAL"

# Combine
fakenewsnet_df = pd.concat([buzzfeed_fake, buzzfeed_real], ignore_index=True)

#  Print the head
print("News Detection :\n", news_df.head(), "\n")
print("Misinformation :\n", misinfo_df.head(), "\n")
print("FakeNewsNet :\n", fakenewsnet_df.head())

#Explore the Datasets and Checking the  shapes, columns and  missing values


for name, df in [("News Detection", news_df), ("Misinformation", misinfo_df), ("FakeNewsNet", fakenewsnet_df)]:
    print(f"\n{name} dataset:")
    print(df.shape)
    print(df.columns)
    print(df.isnull().sum())

import matplotlib.pyplot as plt

news_df['label'].value_counts().plot(kind='bar', title="News Detection Class Distribution")
plt.show()

#makeing  all three datasets share the same schema
# News Detection
news_df = news_df.rename(columns={"Text": "content"})
news_df = news_df[["content", "label"]]

# Misinformation
misinfo_df = misinfo_df.drop(columns=["Unnamed: 0"])  # drop useless index
misinfo_df = misinfo_df.rename(columns={"text": "content"})
misinfo_df = misinfo_df[["content", "label"]]

# FakeNewsNet
# Merge title + text into one field
fakenewsnet_df["content"] = (
    fakenewsnet_df["title"].fillna("") + " " + fakenewsnet_df["text"].fillna("")
)
fakenewsnet_df = fakenewsnet_df[["content", "label"]]

#Checking  Class Labels
def normalize_labels(df):
    df["label"] = df["label"].str.upper().replace({
        "TRUE": "REAL",   # unify TRUE â†’ REAL
        "REAL": "REAL",
        "FAKE": "FAKE",
        "1": "FAKE",      # if dataset used numbers
        "0": "REAL"
    })
    return df

news_df = normalize_labels(news_df)
misinfo_df = normalize_labels(misinfo_df)
fakenewsnet_df = normalize_labels(fakenewsnet_df)

combined_df = pd.concat([news_df, misinfo_df, fakenewsnet_df], ignore_index=True)
print(combined_df["label"].value_counts())
print(combined_df.shape)

#  Imports
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,
                             classification_report, confusion_matrix)
import matplotlib.pyplot as plt

# clean NaNs/empties
df = combined_df.copy()
df = df.dropna(subset=["content"])
df = df[df["content"].str.strip() != ""]

X = df["content"].astype(str)
y = df["label"].astype(str)   # 'FAKE' / 'REAL'

#  Split  for the training
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)

#  TF-IDF  Convert text into numbers that ML can process.
tfidf = TfidfVectorizer(max_features=20_000, ngram_range=(1,2), stop_words="english")
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf  = tfidf.transform(X_test)

# train, predict, score
def evaluate_model(name, model, Xtr, ytr, Xte, yte, show_report=True):
    model.fit(Xtr, ytr)
    preds = model.predict(Xte)
    acc = accuracy_score(yte, preds)
    p, r, f1, _ = precision_recall_fscore_support(yte, preds, average="weighted", zero_division=0)
    if show_report:
        print(f"\n=== {name} ===")
        print(classification_report(yte, preds, zero_division=0))
        cm = confusion_matrix(yte, preds, labels=["FAKE","REAL"])
        print("Confusion Matrix (rows=true, cols=pred):\n", cm)
    return {
        "model": name, "accuracy": acc, "precision": p, "recall": r, "f1": f1,
        "y_pred": preds
    }

# ) Baselines
logreg = LogisticRegression(max_iter=2000, n_jobs=-1, class_weight="balanced")
svm    = LinearSVC()                     # strong for sparse text
rf     = RandomForestClassifier(
            n_estimators=300, max_depth=None, n_jobs=-1, class_weight="balanced_subsample"
        )

results = []
results.append(evaluate_model("LogReg (TF-IDF)", logreg, X_train_tfidf, y_train, X_test_tfidf, y_test))
results.append(evaluate_model("LinearSVC (TF-IDF)", svm, X_train_tfidf, y_train, X_test_tfidf, y_test))
results.append(evaluate_model("RandomForest (TF-IDF)", rf, X_train_tfidf, y_train, X_test_tfidf, y_test))

# Train a Models

# model 1 Logistic Regression C sweep
logreg_grid = GridSearchCV(
    LogisticRegression(max_iter=2000, n_jobs=-1, class_weight="balanced"),
    param_grid={"C":[0.25, 0.5, 1.0, 2.0]},
    scoring="f1_weighted", cv=3, n_jobs=-1
)
logreg_grid.fit(X_train_tfidf, y_train)
best_logreg = logreg_grid.best_estimator_
results.append(evaluate_model("LogReg (tuned)", best_logreg, X_train_tfidf, y_train, X_test_tfidf, y_test))

# model 2 LinearSVC C sweep
svm_grid = GridSearchCV(
    LinearSVC(),
    param_grid={"C":[0.5, 1.0, 2.0]},
    scoring="f1_weighted", cv=3, n_jobs=-1
)
svm_grid.fit(X_train_tfidf, y_train)
best_svm = svm_grid.best_estimator_
results.append(evaluate_model("LinearSVC (tuned)", best_svm, X_train_tfidf, y_train, X_test_tfidf, y_test))

# model 3 RandomForest sweep (kept tiny to be fast)
rf_grid = GridSearchCV(
    RandomForestClassifier(n_jobs=-1, class_weight="balanced_subsample", random_state=42),
    param_grid={"n_estimators":[200, 400], "max_depth":[None, 30]},
    scoring="f1_weighted", cv=3, n_jobs=-1
)
rf_grid.fit(X_train_tfidf, y_train)
best_rf = rf_grid.best_estimator_
results.append(evaluate_model("RandomForest (tuned)", best_rf, X_train_tfidf, y_train, X_test_tfidf, y_test))

#  table for the report
summary = pd.DataFrame([
    {k:v for k,v in r.items() if k in ["model","accuracy","precision","recall","f1"]}
    for r in results
]).sort_values("f1", ascending=False)

print("\n=== Model Comparison (TF-IDF) ===")
display(summary.style.format({"accuracy":"{:.3f}","precision":"{:.3f}","recall":"{:.3f}","f1":"{:.3f}"}))